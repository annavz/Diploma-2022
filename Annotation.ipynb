{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pysrt https://pypi.org/project/pysrt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import pysrt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\..\\data\\Diploma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(path, 'Sex_And_The_City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(os.walk(data_path))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists (os.path.join(data_path, 'german')):\n",
    "    os.mkdir(os.path.join(data_path, 'german'))\n",
    "    for file in files:\n",
    "        flag = '.ger.' in file\n",
    "        if flag:\n",
    "            with ZipFile(os.path.join(data_path, file), 'r') as zipObj:\n",
    "                zipObj.extractall(path=os.path.join(data_path, 'german'))\n",
    "            season_files = list(os.walk(os.path.join(data_path, 'german')))\n",
    "            for file in season_files[1:]:\n",
    "                path_from = os.path.join(file[0], file[2][0])\n",
    "                path_to = os.path.join(data_path, 'german', file[2][0])\n",
    "                os.replace(path_from, path_to)\n",
    "            dirs = list(os.walk(os.path.join(data_path, 'german')))[0][1]\n",
    "            for d in dirs:\n",
    "                os.rmdir(os.path.join(data_path, 'german', d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists (os.path.join(data_path, 'russian')):\n",
    "    os.mkdir(os.path.join(data_path, 'russian'))\n",
    "    for file in files:\n",
    "        flag = '.rus.' in file\n",
    "        if flag:\n",
    "            with ZipFile(os.path.join(data_path, file), 'r') as zipObj:\n",
    "                zipObj.extractall(path=os.path.join(data_path, 'russian'))\n",
    "            season_files = list(os.walk(os.path.join(data_path, 'russian')))\n",
    "            for file in season_files[1:]:\n",
    "                path_from = os.path.join(file[0], file[2][0])\n",
    "                path_to = os.path.join(data_path, 'russian', file[2][0])\n",
    "                os.replace(path_from, path_to)\n",
    "            dirs = list(os.walk(os.path.join(data_path, 'russian')))[0][1]\n",
    "            for d in dirs:\n",
    "                os.rmdir(os.path.join(data_path, 'russian', d))\n",
    "                \n",
    "path_german = list(os.walk(os.path.join(data_path, 'german')))[0][0]\n",
    "files_german = list(os.walk(os.path.join(data_path, 'german')))[0][2]\n",
    "path_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][0]\n",
    "files_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files_german:\n",
    "    if file.endswith('.srt'):\n",
    "        numbers = re.findall('(\\d\\d)x(\\d\\d)|s(\\d\\d)e(\\d\\d)|s(\\d\\d)\\.e(\\d\\d)|(\\d+?)x(\\d\\d)', file.lower())[0]\n",
    "        numbers = list(numbers)\n",
    "        numbers = [i for i in numbers if i != '']\n",
    "        for num, i in enumerate(numbers):\n",
    "            if len(i) == 1:\n",
    "                numbers[num] = '0' + i\n",
    "        old_path = os.path.join(path_german, file)\n",
    "        new_path = os.path.join(path_german, 'S' + numbers[0] + 'E' + numbers[1] + '.srt')\n",
    "        os.rename(old_path, new_path)\n",
    "        \n",
    "for file in files_russian:\n",
    "    if file.endswith('.srt'):\n",
    "        numbers = re.findall('(\\d\\d)x(\\d\\d)|s(\\d\\d)e(\\d\\d)|s(\\d\\d)\\.e(\\d\\d)', file.lower())[0]\n",
    "        numbers = list(numbers)\n",
    "        numbers = [i for i in numbers if i != '']\n",
    "        old_path = os.path.join(path_russian, file)\n",
    "        new_path = os.path.join(path_russian, 'S' + numbers[0] + 'E' + numbers[1] + '.srt')\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists (os.path.join(data_path, 'german')):\n",
    "    os.mkdir(os.path.join(data_path, 'german'))\n",
    "    for file in files:\n",
    "        flag = '.ger.' in file\n",
    "        if flag:\n",
    "            with ZipFile(os.path.join(data_path, file), 'r') as zipObj:\n",
    "                zips = zipObj.namelist()\n",
    "                for z in zips:\n",
    "                    if z.endswith('srt'):\n",
    "                        break\n",
    "                zipObj.extract(member=z, path=os.path.join(data_path, 'german'))\n",
    "if not os.path.exists (os.path.join(data_path, 'russian')):\n",
    "    os.mkdir(os.path.join(data_path, 'russian'))\n",
    "    for file in files:\n",
    "        flag = '.rus.' in file\n",
    "        if flag:\n",
    "            with ZipFile(os.path.join(data_path, file), 'r') as zipObj:\n",
    "                zips = zipObj.namelist()\n",
    "                for z in zips:\n",
    "                    if z.endswith('srt'):\n",
    "                        break\n",
    "                zipObj.extract(member=z, path=os.path.join(data_path, 'russian'))\n",
    "                \n",
    "path_german = list(os.walk(os.path.join(data_path, 'german')))[0][0]\n",
    "files_german = list(os.walk(os.path.join(data_path, 'german')))[0][2]\n",
    "path_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][0]\n",
    "files_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][2]\n",
    "\n",
    "for file in files_german:\n",
    "    if file.endswith('.srt'):\n",
    "        numbers = re.findall('(\\d\\d)x(\\d\\d)|s(\\d\\d)e(\\d\\d)|s(\\d\\d)\\.e(\\d\\d)|(\\d+?)x(\\d\\d)', file.lower())[0]\n",
    "        numbers = list(numbers)\n",
    "        numbers = [i for i in numbers if i != '']\n",
    "        for num, i in enumerate(numbers):\n",
    "            if len(i) == 1:\n",
    "                numbers[num] = '0' + i\n",
    "        old_path = os.path.join(path_german, file)\n",
    "        new_path = os.path.join(path_german, 'S' + numbers[0] + 'E' + numbers[1] + '.srt')\n",
    "        os.rename(old_path, new_path)\n",
    "        \n",
    "for file in files_russian:\n",
    "    if file.endswith('.srt'):\n",
    "        numbers = re.findall('(\\d\\d)x(\\d\\d)|s(\\d\\d)e(\\d\\d)|s(\\d\\d)\\.e(\\d\\d)', file.lower())[0]\n",
    "        numbers = list(numbers)\n",
    "        numbers = [i for i in numbers if i != '']\n",
    "        old_path = os.path.join(path_russian, file)\n",
    "        new_path = os.path.join(path_russian, 'S' + numbers[0] + 'E' + numbers[1] + '.srt')\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aligning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aligning(german_text, russian_text, alphabet=set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя')): \n",
    "    if german_text[-1].end > russian_text[-1].end:\n",
    "        later = german_text\n",
    "        ealier = russian_text\n",
    "    else:\n",
    "        later = russian_text\n",
    "        ealier = german_text\n",
    "\n",
    "    indexes = []\n",
    "    for text in later:\n",
    "        diffs = [(sec_text.start - text.start) for sec_text in ealier]\n",
    "        diffs = [(((diff.hours * 60 + \n",
    "                 diff.minutes) * 60 +\n",
    "                 diff.seconds) * 1000 +\n",
    "                 diff.milliseconds)**2 for diff in diffs]\n",
    "        diffs = np.array(diffs)\n",
    "        minimum = np.argmin(diffs)\n",
    "        indexes.append(minimum)\n",
    "    ealier_analogue = [ealier[i] for i in indexes]\n",
    "    if set(ealier_analogue[5].text).isdisjoint(alphabet):\n",
    "        russian_text = later\n",
    "        german_text = ealier_analogue\n",
    "    else:\n",
    "        russian_text = ealier_analogue\n",
    "        german_text = later\n",
    "    return german_text, russian_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiling(german_text, russian_text):\n",
    "    final = dict()\n",
    "    for num, ger_text in enumerate(german_text):\n",
    "        final[num] = dict()\n",
    "        doc_ger = nlp_ger(ger_text.text)\n",
    "        tokens_ger = [w.text for w in doc_ger]\n",
    "        doc_rus = nlp_rus(russian_text[num].text)\n",
    "        tokens_rus = [w.text for w in doc_rus]\n",
    "        final[num]['german'] = ger_text.text\n",
    "        final[num]['russian'] = russian_text[num].text\n",
    "        final[num]['german_tokens'] = tokens_ger\n",
    "        final[num]['russian_tokens'] = tokens_rus\n",
    "        final[num]['has_DF'] = ''\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_german = list(os.walk(os.path.join(data_path, 'german')))[0][0]\n",
    "files_german = list(os.walk(os.path.join(data_path, 'german')))[0][2]\n",
    "files_german = [file for file in files_german if file.endswith('srt')]\n",
    "path_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][0]\n",
    "files_russian = list(os.walk(os.path.join(data_path, 'russian')))[0][2]\n",
    "files_russian = [file for file in files_russian if file.endswith('srt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists (os.path.join(data_path, 'jsons')):\n",
    "    os.mkdir(os.path.join(data_path, 'jsons'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:12,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:58,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:10,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [01:21,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [01:26,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [01:32,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [01:44,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:56,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [02:02,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [02:08,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [02:13,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01E24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [02:19,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for ger_file, rus_file in tqdm(zip(files_german, files_russian)):\n",
    "    filename = ger_file.split('.')[0]\n",
    "    if ger_file == rus_file:\n",
    "        try:\n",
    "            german_text = pysrt.open(os.path.join(path_german, ger_file), encoding='utf-8')\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(filename)\n",
    "            german_text = pysrt.open(os.path.join(path_german, ger_file), encoding='latin-1')\n",
    "        try:\n",
    "            russian_text = pysrt.open(os.path.join(path_russian, rus_file), encoding='utf-8')\n",
    "        except UnicodeDecodeError as e:\n",
    "            russian_text = pysrt.open(os.path.join(path_russian, rus_file), encoding='Windows-1251')\n",
    "        german_text, russian_text = aligning(german_text, russian_text)\n",
    "        nlp_ger = spacy.load('de_core_news_sm')\n",
    "        nlp_rus = spacy.load('ru_core_news_sm')\n",
    "        dictionary = compiling(german_text, russian_text)\n",
    "        with open(os.path.join(data_path, 'jsons', filename + '.json'), 'w', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(dictionary, ensure_ascii=False))\n",
    "    else:\n",
    "        print(ger_file, rus_file)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'DFs.json'), 'r', encoding='utf-8') as f:\n",
    "    dfs = f.read()\n",
    "    dfs = json.loads(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = list(os.walk(os.path.join(path, 'Friends', 'jsons')))[0][0]\n",
    "files = list(os.walk(os.path.join(path, 'Friends', 'jsons')))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 348/348 [00:01<00:00, 347.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 355/355 [00:01<00:00, 347.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 357/357 [00:01<00:00, 339.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 373/373 [00:00<00:00, 380.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 316/316 [00:00<00:00, 406.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 342/342 [00:00<00:00, 394.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 307/307 [00:00<00:00, 399.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:00<00:00, 391.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 301/301 [00:00<00:00, 391.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 321/321 [00:00<00:00, 370.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 356/356 [00:00<00:00, 371.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 341/341 [00:00<00:00, 416.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 318/318 [00:00<00:00, 419.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 317/317 [00:00<00:00, 405.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 336/336 [00:00<00:00, 395.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 354/354 [00:00<00:00, 392.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 345/345 [00:00<00:00, 407.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 328/328 [00:00<00:00, 402.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 365.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 387/387 [00:01<00:00, 380.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 315/315 [00:00<00:00, 392.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 358/358 [00:00<00:00, 418.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 353/353 [00:00<00:00, 407.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 334/334 [00:00<00:00, 397.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    with open(os.path.join(file_path, filename), 'r', encoding='utf-8') as f:\n",
    "        file = f.read()\n",
    "        file = json.loads(file)\n",
    "    for key, value in tqdm(file.items()):\n",
    "        detected_dfs = []\n",
    "        rus = value['russian']\n",
    "        ger = value['german']\n",
    "        rus_tokens = value['russian_tokens']\n",
    "        ger_tokens = value['german_tokens']\n",
    "        for df, df_tokens in dfs['russian'].items():\n",
    "            f = 0\n",
    "            for df_token in df_tokens:\n",
    "                if df_token in rus_tokens:\n",
    "                    f += 1\n",
    "            if (df.lower() in rus.lower()) and (f == len(df_tokens)):\n",
    "                detected_dfs.append(df)\n",
    "        for df, df_tokens in dfs['german'].items():\n",
    "            f = 0\n",
    "            for df_token in df_tokens:\n",
    "                if df_token in ger_tokens:\n",
    "                    f += 1\n",
    "            if (df.lower() in ger.lower()) and (f == len(df_tokens)):\n",
    "                detected_dfs.append(df)\n",
    "        if len(detected_dfs):\n",
    "            file[key]['has_DF'] = True\n",
    "        file[key]['DFs'] = detected_dfs\n",
    "        with open(os.path.join(file_path, filename), 'w', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(file, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schon gut\n",
    "tja - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
